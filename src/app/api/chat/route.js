import { getDb } from "@/app/lib/db";
import { getChatMessageModel } from "@/app/lib/models/ChatMessage";
import { NextResponse } from 'next/server';
import OpenAI from "openai";
import { verifyToken } from "@/app/lib/verifyToken";
import { safeJsonParse } from "@/app/lib/ai/utils";
import { tools, systemPrompt } from "@/app/lib/ai/config";
import * as handlers from "@/app/lib/ai/handlers";

const apiKey = process.env.OPENAI_API_KEY;
const openai = new OpenAI({
  apiKey: apiKey,
  baseURL: apiKey?.startsWith('sk-or-v1') ? "https://openrouter.ai/api/v1" : undefined
});

const undoHistory = new Map(); // userId -> undoData

// ================== GET CHAT HISTORY ==================
export async function GET(req) {
  try {
    const user = verifyToken(req.headers);
    if (!user) return NextResponse.json({ message: "ØºÙŠØ± Ù…ØµØ±Ø­ Ù„Ùƒ" }, { status: 401 });

    const conn = await getDb(user.pharmacyId);
    const ChatMessage = getChatMessageModel(conn);

    const history = await ChatMessage.find({
      pharmacyId: user.pharmacyId,
      userId: user.userId
    })
      .sort({ createdAt: -1 })
      .limit(30)
      .lean();

    return NextResponse.json(history.reverse());
  } catch (e) {
    console.error(e);
    return NextResponse.json({ message: "Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø³Ø¬Ù„" }, { status: 500 });
  }
}

// ================== DELETE (CLEAR HISTORY) ==================
export async function DELETE(req) {
  try {
    const user = verifyToken(req.headers);
    if (!user) return NextResponse.json({ message: "ØºÙŠØ± Ù…ØµØ±Ø­ Ù„Ùƒ" }, { status: 401 });

    const conn = await getDb(user.pharmacyId);
    const ChatMessage = getChatMessageModel(conn);

    await ChatMessage.deleteMany({
      pharmacyId: user.pharmacyId,
      userId: user.userId
    });

    return NextResponse.json({ message: "ØªÙ… Ù…Ø³Ø­ Ø³Ø¬Ù„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø¨Ù†Ø¬Ø§Ø­" });
  } catch (e) {
    console.error(e);
    return NextResponse.json({ message: "Ø®Ø·Ø£ ÙÙŠ Ù…Ø³Ø­ Ø§Ù„Ø³Ø¬Ù„" }, { status: 500 });
  }
}

// ================== POST ROUTE (CHAT) ==================
export async function POST(req) {
  console.log("ğŸŸ¢ Chat POST started");

  try {
    const body = await req.json();
    console.log("ğŸ“¥ Request body:", body);

    const { message } = body;

    const user = verifyToken(req.headers);
    console.log("ğŸ‘¤ Verified user:", user);

    if (!user) {
      console.warn("â›” Unauthorized request");
      return NextResponse.json(
        { message: "ØºÙŠØ± Ù…ØµØ±Ø­", actions: [] },
        { status: 401 }
      );
    }

    if (!process.env.OPENAI_API_KEY) {
      console.error("âŒ Missing OPENAI_API_KEY");
      return NextResponse.json(
        { message: "OPENAI_API_KEY Ù…Ø´ Ù…ÙˆØ¬ÙˆØ¯" },
        { status: 500 }
      );
    }

    const authHeader = req.headers.get("authorization");
    const token = authHeader?.split(" ")[1];
    console.log("ğŸ” Token extracted:", !!token);

    const ChatMessage = getChatMessageModel(await getDb(user.pharmacyId));
    console.log("ğŸ—„ï¸ ChatMessage model ready");

    // 1. Save User Message
    await ChatMessage.create({
      pharmacyId: user.pharmacyId,
      userId: user.userId,
      role: "user",
      content: message
    });
    console.log("ğŸ’¾ User message saved");

    // 2. Load History (Reduced to 25 to prevent context saturation/stupidity)
    const history = await ChatMessage.find({
      pharmacyId: user.pharmacyId,
      userId: user.userId
    })
      .sort({ createdAt: -1 })
      .limit(25)
      .lean();

    console.log("ğŸ“œ Loaded history count:", history.length);

    // 3. Build Context (Keep tool messages linked to assistant tool_calls)
    const context = history.reverse().map(m => {
      const msg = { role: m.role, content: m.content || null };

      if (m.role === "assistant" && m.tool_calls && m.tool_calls.length > 0) {
        msg.tool_calls = m.tool_calls;
      }

      if (m.role === "tool") {
        msg.tool_call_id = m.tool_call_id;
        msg.name = m.name;
        msg.content = m.content || "";
      }

      return msg;
    });

    console.log("ğŸ§  Context mapped");

    // 4. Filter orphaned tool messages AND assistant calls without tool results
    // OpenAI/OpenRouter fail if:
    // - A tool response exists without a tool call
    // - A tool call exists without a tool response
    const finalContext = [];
    const availableToolResults = new Set(context.filter(m => m.role === "tool").map(m => m.tool_call_id));
    const availableToolCalls = new Set();
    context.forEach(m => {
      if (m.role === "assistant" && m.tool_calls) {
        m.tool_calls.forEach(tc => availableToolCalls.add(tc.id));
      }
    });

    for (const msg of context) {
      if (msg.role === "assistant" && msg.tool_calls) {
        // Only keep tool_calls that have matching results in the context
        const matchedCalls = msg.tool_calls.filter(tc => availableToolResults.has(tc.id));
        if (matchedCalls.length > 0) {
          finalContext.push({ ...msg, tool_calls: matchedCalls });
        } else if (msg.content) {
          // If no tool results match but there is text content, keep just the text
          const { tool_calls, ...justText } = msg;
          finalContext.push(justText);
        } else {
          console.warn("âš ï¸ Skipping assistant message with no matching results and no content");
        }
      } else if (msg.role === "tool") {
        if (availableToolCalls.has(msg.tool_call_id)) {
          finalContext.push(msg);
        } else {
          console.warn("âš ï¸ Orphan tool message skipped:", msg.tool_call_id);
        }
      } else {
        finalContext.push(msg);
      }
    }

    const messages = [
      { role: "system", content: systemPrompt },
      ...finalContext
    ];

    console.log("ğŸ“¨ Messages sent to OpenAI:", messages.length);

    // 5. Single Turn Interaction (Removed sequential loop at user request)
    const completion = await openai.chat.completions.create({
      model: "openai/gpt-oss-20b",
      messages,
      tools,
      tool_choice: "auto",
      max_tokens: 2000
    });

    if (!completion?.choices?.length) {
      console.warn("âš ï¸ Empty completion from OpenAI");
      return NextResponse.json({ message: "Ù„Ù… ÙŠØªÙ…ÙƒÙ† Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ù…Ù† Ø§Ù„Ø±Ø¯." });
    }

    const msg = completion.choices[0].message;
    const reasoning = msg.reasoning || (msg.reasoning_details?.length ? msg.reasoning_details[0].text : "");
    if (reasoning) console.log("ğŸ§  Reasoning:", reasoning);

    console.log("ğŸ¤– Assistant message:", msg);
    messages.push(msg);

    // No tools â†’ final response
    if (!msg.tool_calls || msg.tool_calls.length === 0) {
      const content = msg.content || reasoning || "ØªÙ…Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­.";
      await ChatMessage.create({
        pharmacyId: user.pharmacyId,
        userId: user.userId,
        role: "assistant",
        content: content
      });

      console.log("âœ… Final assistant response sent");

      return NextResponse.json({
        message: content,
        data: null,
        type: null
      });
    }

    // Save assistant tool calls
    await ChatMessage.create({
      pharmacyId: user.pharmacyId,
      userId: user.userId,
      role: "assistant",
      tool_calls: msg.tool_calls,
      content: msg.content || null
    });

    console.log("ğŸ§° Tool calls detected:", msg.tool_calls.length);

    let finalResult = null;
    let lastToolName = null;
    let errors = [];

    for (const call of msg.tool_calls) {
      if (!call?.function?.name || String(call.function.name) === 'undefined') {
        console.warn("âš ï¸ Skipping malformed tool call:", call);
        continue;
      }

      // Sanitize tool name from garbage tokens (like <|channel|>commentary)
      const rawToolName = String(call.function.name).trim().split(/[<\s(]/)[0];
      console.log("ğŸ”§ Tool call:", rawToolName);

      let args;
      let result = null;
      lastToolName = call.function.name;

      try {
        args = safeJsonParse(call.function.arguments);
        console.log("ğŸ“¦ Tool args:", args);
      } catch (e) {
        console.error("âŒ Failed to parse tool args", e);
        result = { error: e.message };
      }

      if (!result) {
        try {
          const handlerName =
            "handle" +
            rawToolName
              .split("_")
              .map(s => s.charAt(0).toUpperCase() + s.slice(1))
              .join("");

          console.log("â¡ï¸ Handler:", handlerName);

          if (handlers[handlerName]) {
            const currentUndoData = undoHistory.get(user.userId);
            result = await handlers[handlerName](token, args, currentUndoData);
            console.log("âœ… Tool result:", result);

            if (result?.undoData) {
              undoHistory.set(user.userId, result.undoData);
              console.log("â†©ï¸ Undo data saved");
            }
          } else {
            console.error("âŒ Unsupported tool:", call.function.name);
            result = { error: `Ø£Ø¯Ø§Ø© ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…Ø©: ${call.function.name}` };
          }
        } catch (e) {
          console.error(`âŒ Tool error (${call.function.name})`, e);
          result = { error: e.message };
        }
      }

      if (result?.error) {
        errors.push(result.error);
      }
      finalResult = result;

      const toolMsg = {
        role: "tool",
        tool_call_id: call.id,
        name: call.function.name,
        content: JSON.stringify(result)
      };

      await ChatMessage.create({
        pharmacyId: user.pharmacyId,
        userId: user.userId,
        ...toolMsg
      });

      messages.push(toolMsg);
      console.log("ğŸ“¤ Tool response pushed to context");
    }

    // After tool execution, we return the result.
    // The AI doesn't get another turn here, so it will wait for the user to message again.
    let finalMessage = "ØªÙ… ØªÙ†ÙÙŠØ° Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­. Ù‡Ù„ Ù‡Ù†Ø§Ùƒ Ø´ÙŠØ¡ Ø¢Ø®Ø±ØŸ";

    if (errors.length > 0) {
      finalMessage = `Ø¹Ø°Ø±Ø§Ù‹ØŒ ÙØ´Ù„Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ©: ${errors[0]}`;
    } else if (finalResult?.message) {
      // Use the specific message from the handler if it exists
      finalMessage = finalResult.message;
    } else if (lastToolName === 'search_products') {
      if (Array.isArray(finalResult) && finalResult.length === 0) {
        finalMessage = "Ù„Ù… Ø£Ø¬Ø¯ Ø£ÙŠ Ù…Ù†ØªØ¬Ø§Øª ØªØ·Ø§Ø¨Ù‚ Ø¨Ø­Ø«Ùƒ.";
      } else if (Array.isArray(finalResult)) {
        finalMessage = `ÙˆØ¬Ø¯Øª ${finalResult.length} Ù…Ù† Ø§Ù„Ù†ØªØ§Ø¦Ø¬. Ø§ØªÙØ¶Ù„ Ø´ÙˆÙ Ø§Ù„Ø¬Ø¯ÙˆÙ„Ø© ÙÙˆÙ‚.`;
      }
    }

    return NextResponse.json({
      message: finalMessage,
      data: finalResult,
      type: lastToolName
    });

    console.warn("â›” Max loops reached");
    console.log("ğŸ§¾ Final result:", finalResult);

    return NextResponse.json({
      message: "ÙˆØµÙ„ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ù„Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù…Ù† Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…ØªØªØ§Ù„ÙŠØ©.",
      data: finalResult,
      type: lastToolName
    });
  } catch (e) {
    console.error("ğŸ”¥ Fatal error in chat POST:", e);
    return NextResponse.json(
      { message: "Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø®Ø§Ø¯Ù…" },
      { status: 500 }
    );
  }
}
